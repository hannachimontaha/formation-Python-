{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhZhRB+ULbmg59o2mlrctI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yjzcR-ZYB60u","executionInfo":{"status":"ok","timestamp":1716971471646,"user_tz":-60,"elapsed":4,"user":{"displayName":"montaha hannachi","userId":"06585443957193785496"}}},"outputs":[],"source":["from google.colab import drive"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"1ZJ5tGQzCIUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716971556620,"user_tz":-60,"elapsed":79674,"user":{"displayName":"montaha hannachi","userId":"06585443957193785496"}},"outputId":"4677969c-c44c-4ab3-aeee-c618fe0da357"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["############################# 1.Importation des bibliothèques #############################\n","\n","#Pour l'interaction avec le système d'exploitation\n","import os\n","import cv2\n","#Pour manipuler les tableaux\n","import numpy as np\n","\n","#Encoding and Split data into Train/Test Sets\n","#Pour encoder les étiquettes de classe\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","#Tensorflow Keras CNN Model\n","#pour la création et l'entraînement du modèle CNN\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n","\n","#Plot Images\n","#Pour afficher des images\n","import matplotlib.pyplot as plt\n","\n","\n","############################# 2.Chargement et prétraitement des images #############################\n","\n","#Définition du répertoire contenant les images de fleurs\n","folder_dir = '/content/drive/MyDrive/flowers'\n","\n","#Initialisation de listes pour stocker les données (images) et les étiquettes (labels)\n","data = []\n","label = []\n","\n","SIZE = 128 #Crop the image to 128x128\n","\n","# Cette partie lit les images d'un répertoire spécifié, les convertit en format RGB,\n","# les redimensionne à une taille définie (128x128 pixels), et les stocke dans data.\n","# Les étiquettes correspondantes sont stockées dans la liste label.\n","for folder in os.listdir(folder_dir):\n","    for file in os.listdir(os.path.join(folder_dir, folder)):\n","        if file.endswith(\"jpg\"):\n","            label.append(folder)\n","            img = cv2.imread(os.path.join(folder_dir, folder, file))\n","            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            im = cv2.resize(img_rgb, (SIZE,SIZE))\n","            data.append(im)\n","        else:\n","            continue\n","\n","# Conversion des listes en tableaux NumPy\n","data_arr = np.array(data)\n","label_arr = np.array(label)\n","\n","############################# 3.Encodage des étiquettes et division des données #############################\n","\n","# Les étiquettes sont encodées en nombres entiers, puis en vecteurs binaires\n","encoder = LabelEncoder()\n","y = encoder.fit_transform(label_arr)\n","y = to_categorical(y,5)\n","# Les valeurs des pixels des images sont normalisées en les divisant par 255\n","X = data_arr/255\n","# Séparation des données en ensembles d'entraînement (X_train, y_train) et de test (X_test, y_test) à l'aide de train_test_split.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n","\n","############################# 4.Création du modèle CNN #############################\n","\n","#Ce code définit la structure d'un modèle de réseau de neurones convolutionnel (CNN) à l'aide de l'interface séquentielle de Keras,\n","#qui est un composant de TensorFlow.\n","\n","#Ces lignes de code définissent l’architecture du modèle CNN.\n","\n","model = Sequential()\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#Le modèle est composé de plusieurs couches de convolution et de pooling, suivies d’une couche de flattening et de couches fully connected\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(rate=0.5))\n","#La dernière couche utilise une activation softmax pour produire une distribution de probabilités sur les 5 catégories\n","model.add(Dense(5, activation = \"softmax\"))\n","\n","############################# 5.Augmentation des données #############################\n","# Ces lignes de code créent un générateur de données qui applique des transformations aléatoires aux images\n","# d’entraînement pour augmenter la diversité des données\n","datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range = 0.20,\n","        width_shift_range=0.3,\n","        height_shift_range=0.3,\n","        horizontal_flip=True,\n","        vertical_flip=True)\n","\n","datagen.fit(X_train)\n","\n","############################# 6.Compilation et entraînement du modèle #############################\n","\n","#le modèle est compilé avec l’optimiseur Adam, la perte de catégorie croisée catégorique, et la métrique de précision.\n","#Le modèle est ensuite entraîné en utilisant le générateur de données.\n","\n","model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n","batch_size=32\n","epochs=64\n","\n","history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n","                              epochs = epochs,\n","                              validation_data = (X_test,y_test),\n","                              verbose = 1)\n","\n","############################# 7.Visualisation des résultats #############################\n","\n","#Ces lignes de code affichent un échantillon d’images de test avec les étiquettes réelles et prédites.\n","#Si la prédiction est correcte, le titre et le sous-titre sont affichés en vert, sinon en rouge.\n","categories = np.sort(os.listdir(folder_dir))\n","fig, ax = plt.subplots(6,6, figsize=(25, 40))\n","for i in range(6):\n","    for j in range(6):\n","        k = int(np.random.random_sample() * len(X_test))\n","        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n","            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n","            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n","            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n","        else:\n","            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n","            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n","            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10YTb4waCOHcc2DOgXlHek69aGliy4iHH"},"id":"66P9jwvyChlS","executionInfo":{"status":"ok","timestamp":1716972677281,"user_tz":-60,"elapsed":1114689,"user":{"displayName":"montaha hannachi","userId":"06585443957193785496"}},"outputId":"3100fc18-b8ff-485d-f4db-59ebc7822247"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}